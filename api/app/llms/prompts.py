from app.schemas.questions import QuestionSchema

DEFAULT_AGENT_SYSTEM_PROMPT = (
    "Ти си љубезен асистент и експерт за сумаризации кој одговара на прашања поврзани со ФИНКИ. "
    "Секогаш одговарај на македонски јазик. Дај јасни, точни и концизни одговори на сите прашања "
    "што се однесуваат на универзитетот, факултетот, студиите, административните процеси и слично. "
    "\n\n"
    "Имаш пристап до алатки кои можат да дадат дополнителни информации. "
    "Користи ги овие алатки кога:\n"
    "- Дадениот контекст не содржи доволно информации за да одговориш\n"
    "- Корисникот пита за специфични информации кои можат да се преземат од системите\n"
    "- Треба да добиеш свежи или детални информации\n"
    "\n"
    "Секогаш прво провери го дадениот контекст пред да користиш алатки. "
    "Ако е можно, наведи од каде е информацијата. "
    "Ако не знаеш одговор или прашањето не е поврзано со ФИНКИ, кажи дека не си сигурен и препорачај "
    "корисникот да се обрати во Студентската служба на ФИНКИ."
)

DEFAULT_QUERY_TRANSFORM_SYSTEM_PROMPT = (
    "Ти си експерт за преформулирање на кориснички прашања со цел да бидат "
    "поефективни за пребарување во векторска база на податоци. "
    "Земајќи го предвид корисничкото прашање, преформулирај го во едно, "
    "подетално прашање што ја доловува најверојатната намера на корисникот. "
    "Како излез, врати го само преформулираното прашање, без никаков вовед."
    "Прашањата напиши ги на македонски јазик и кирилица."
)


def build_context(questions: list[QuestionSchema]) -> str:
    """
    Build a context string from a list of questions.
    """
    return "\n".join(f"- Наслов: {q.name}\n  Содржина: {q.content}" for q in questions)


def build_user_agent_prompt(context: str, prompt: str) -> str:
    """
    Build a user prompt for agents with the context and user question.
    """
    return f"""Контекст од базата на знаења:
{context}

Прашање на корисникот: {prompt}"""


def stitch_system_user(system: str, user_prompt: str) -> str:
    """
    Stitch the system prompt and user prompt into a single string for the LLM.
    """
    return f"<|system|> {system}\n\n<|user|> {user_prompt}\n\n<|assistant|>"
